{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Leer Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos : Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Train Shape :  (712, 5)\n",
      "Titanic Test Shape :  (712, 5)\n",
      "Titanic Shape:  (1043, 5)\n"
     ]
    }
   ],
   "source": [
    "train_titanic = pd.read_csv('titanic_train.csv', sep=',')\n",
    "test_t = pd.read_csv('titanic_test.csv', sep=',')\n",
    "gender_sub = pd.read_csv('gender_submission.csv', sep=',')\n",
    "gender_sub.PassengerId = gender_sub.PassengerId.astype(float)\n",
    "\n",
    "train_titanic = train_titanic.replace('Q', 0)\n",
    "train_titanic = train_titanic.replace('S', 1)\n",
    "train_titanic = train_titanic.replace('C', 2)\n",
    "train_titanic = train_titanic.replace('male', 0)\n",
    "train_titanic = train_titanic.replace('female', 1)\n",
    "train_titanic = np.array(train_titanic.loc[:,['Sex','Age','Fare','Embarked', 'Survived']])\n",
    "train_titanic = train_titanic[~np.isnan(train_titanic).any(axis=1)]\n",
    "\n",
    "print(\"Titanic Train Shape : \", train_titanic.shape)\n",
    "\n",
    "test1_t = pd.merge(test_t, gender_sub,  how='left', on='PassengerId')\n",
    "test1_t = test1_t.replace('Q', 0)\n",
    "test1_t = test1_t.replace('S', 1)\n",
    "test1_t = test1_t.replace('C', 2)\n",
    "test1_t = test1_t.replace('male', 0)\n",
    "test1_t = test1_t.replace('female', 1)\n",
    "\n",
    "print(\"Titanic Test Shape : \", train_titanic.shape)\n",
    "\n",
    "test_titanic = np.array(test1_t.loc[:,['Sex','Age','Fare','Embarked', 'Survived']])\n",
    "test_titanic = test_titanic[~np.isnan(test_titanic).any(axis=1)]\n",
    "\n",
    "titanic = np.concatenate((train_titanic, test_titanic), axis=0)\n",
    "titanic = pd.DataFrame(data=titanic, columns=['Sex','Age','Fare','Embarked', 'Survived'])\n",
    "\n",
    "print(\"Titanic Shape: \", titanic.shape)\n",
    "\n",
    "titanic.to_csv('titanic_all.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos : Glass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos:\n",
    "1. Número de identificación: 1 a 214\n",
    "2. RI: índice de refracción\n",
    "3. Na: Sodio (unidad de medida: porcentaje en peso en el óxido correspondiente, al igual que los atributos 4-10)\n",
    "4. Mg: magnesio\n",
    "5. Al: Aluminio\n",
    "6. Si: silicio\n",
    "7. K: Potasio\n",
    "8. Ca: calcio\n",
    "9. Ba: bario\n",
    "10. Fe: Hierro\n",
    "11. Tipo de vidrio: (atributo de clase)\n",
    "     1. building_windows_float_processed\n",
    "     2. building_windows_non_float_processed\n",
    "     3. vehicle_windows_float_processed\n",
    "     4. vehicle_windows_non_float_processed (ninguno en esta base de datos)\n",
    "     5. contenedores\n",
    "     6. vajilla\n",
    "     7. faros\n",
    "    \n",
    "    \n",
    "Distribución de clases: (de un total de 214 instancias)\n",
    "\n",
    "1. 163 Vidrio de ventana (ventanas de edificios y ventanas de vehículos)\n",
    "     1. 87 flotador procesado\n",
    "         - 70 ventanas de construcción\n",
    "         - 17 ventanas de vehículos\n",
    "     2. 76 procesado sin flotación\n",
    "         - 76 ventanas de construcción\n",
    "         - 0 ventanas de vehículos\n",
    "2. 51 Vidrio no de ventana\n",
    "     - 13 contenedores\n",
    "     - 9 vajillas\n",
    "     - 29 faros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glass shape:  (213, 11)\n"
     ]
    }
   ],
   "source": [
    "glass = pd.read_csv('glass.csv')\n",
    "glass.columns = ['id','ri','na','mg','al','si','k','ca','ba','fe','class']\n",
    "print(\"Glass shape: \", glass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal.length  sepal.width  petal.length  petal.width  variety\n",
      "0             5.1          3.5           1.4          0.2        0\n",
      "1             4.9          3.0           1.4          0.2        0\n",
      "2             4.7          3.2           1.3          0.2        0\n",
      "3             4.6          3.1           1.5          0.2        0\n",
      "4             5.0          3.6           1.4          0.2        0\n",
      "..            ...          ...           ...          ...      ...\n",
      "145           6.7          3.0           5.2          2.3        2\n",
      "146           6.3          2.5           5.0          1.9        2\n",
      "147           6.5          3.0           5.2          2.0        2\n",
      "148           6.2          3.4           5.4          2.3        2\n",
      "149           5.9          3.0           5.1          1.8        2\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "Iris shape:  (150, 5)\n"
     ]
    }
   ],
   "source": [
    "iris_data = pd.read_csv('iris.csv')\n",
    "iris_data = iris_data.replace('Setosa', 0)\n",
    "iris_data = iris_data.replace('Versicolor', 1)\n",
    "iris_data = iris_data.replace('Virginica', 2)\n",
    "iris_data.to_csv('iris_all.csv',index=False)\n",
    "print(\"Iris shape: \", iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leer_Datos(file_name):\n",
    "    return pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Normalizar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalizar_Datos(data):\n",
    "    mean_data = np.mean(data)\n",
    "    standard_dev = np.std(data)\n",
    "    data = data - mean_data\n",
    "    data = data / standard_dev\n",
    "    return data, mean_data, standard_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoidal(z):\n",
    "    return 1.0 / (1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dSigmoidal(Z):\n",
    "    s = Sigmoidal(Z)\n",
    "    return np.multiply(s, 1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcular_Funcion_Costo(X, y):\n",
    "    result = np.sum((y * np.log(X)) + ((1 - y) * np.log(1 - X)))\n",
    "    result = (-result) / y.shape[1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Activacion(X, W, b):\n",
    "    Z = np.matmul(W, X) + b\n",
    "    A = Sigmoidal(Z)\n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcular_Accuracy(X, y, W_dict, b_dict):\n",
    "    _, A_dict = Forward(X, W_dict, b_dict)\n",
    "    A_L = A_dict[\"A%d\" % (len(A_dict) - 1)]\n",
    "    result = A_L > 0.5\n",
    "    result = np.logical_xor(np.logical_not(result), y)\n",
    "    return np.sum(result) / y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep(data):\n",
    "    n = data.shape[0]\n",
    "    X = data[:n - 1, :]\n",
    "    y = data[n - 1:, :]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def Crear_k_folds(data, k):\n",
    "    size_fold = int(data.shape[1] / k)\n",
    "    remainder_size_fold = int(data.shape[1] % k)\n",
    "    data = data[:, :data.shape[1] - remainder_size_fold]\n",
    "    k_folds = []\n",
    "    idx_col = 0\n",
    "    for i in range(k):\n",
    "        X, y = sep(data[:, idx_col:idx_col + size_fold])\n",
    "        k_folds.append({\"X\": X, \"y\": y})\n",
    "        idx_col += size_fold\n",
    "    return k_folds, size_fold\n",
    "\n",
    "\n",
    "def Crear_Entrenamiento_Prueba(data):\n",
    "    num_cols = data.shape[1]\n",
    "    train_percentage = 0.7\n",
    "    col_split_data = int(num_cols * train_percentage)\n",
    "    training, test = data[:, :col_split_data], data[:, col_split_data:]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def Crear_Bias(n_actual):\n",
    "    return np.random.rand(n_actual, 1)\n",
    "\n",
    "\n",
    "def Crear_Pesos(n_anterior, n_actual):\n",
    "    return np.random.rand(n_actual, n_anterior)\n",
    "\n",
    "\n",
    "def Crear_W_b_dict(model_mlp):\n",
    "    W_dict = {}\n",
    "    b_dict = {}\n",
    "    for l in range(len(model_mlp) - 1):\n",
    "        W_dict[\"W%d\" % (l + 1)] = Crear_Pesos(model_mlp[l], model_mlp[l + 1])\n",
    "        b_dict[\"b%d\" % (l + 1)] = Crear_Bias(model_mlp[l + 1])\n",
    "    return W_dict, b_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Forward(X, W_dict, b_dict):\n",
    "    A = X\n",
    "    Z_dict = {}\n",
    "    A_dict = {\"A0\": A}\n",
    "    for l in range(len(W_dict)):\n",
    "        A, Z = Activacion(A, W_dict[\"W%d\" % (l + 1)], b_dict[\"b%d\" % (l + 1)])\n",
    "        Z_dict[\"Z%d\" % (l + 1)] = Z\n",
    "        A_dict[\"A%d\" % (l + 1)] = A\n",
    "    return Z_dict, A_dict\n",
    "\n",
    "\n",
    "def get_dC_dA_L(A_L, y):\n",
    "    return -np.divide(y, A_L) + np.divide(1 - y, 1 - A_L)\n",
    "\n",
    "\n",
    "def Backward(W_dict, b_dict, Z_dict, A_dict, y, learn_rate):\n",
    "    m = A_dict[\"A0\"].shape[1]\n",
    "    dA = get_dC_dA_L(A_dict[\"A%d\" % (len(A_dict) - 1)], y)\n",
    "    for l in reversed(range(len(W_dict))):\n",
    "        dZ = np.multiply(dA, dSigmoidal(Z_dict[\"Z%d\" % (l + 1)]))\n",
    "        dW = np.divide(np.dot(dZ, A_dict[\"A%d\" % (l)].T), m)\n",
    "        db = np.divide(np.sum(dZ, axis=1, keepdims=True), m)\n",
    "        dA = np.dot(W_dict[\"W%d\" % (l + 1)].T, dZ)\n",
    "        W_dict[\"W%d\" % (l + 1)] = W_dict[\"W%d\" % (l + 1)] - np.multiply(learn_rate, dW)\n",
    "        b_dict[\"b%d\" % (l + 1)] = b_dict[\"b%d\" % (l + 1)] - np.multiply(learn_rate, db)\n",
    "    return W_dict, b_dict\n",
    "\n",
    "\n",
    "def Gradiente_Descendiente(X, y, W_dict, b_dict, num_iter, learn_rate):\n",
    "    costs = np.zeros(num_iter)\n",
    "    for i in range(num_iter):\n",
    "        Z_dict, A_dict = Forward(X, W_dict, b_dict)\n",
    "        W_dict, b_dict = Backward(W_dict, b_dict, Z_dict, A_dict, y, learn_rate)\n",
    "        costs[i] = Calcular_Funcion_Costo(A_dict[\"A%d\" % (len(A_dict) - 1)], y)\n",
    "    return W_dict, b_dict, costs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1043)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "[4, 1]\n",
      "0.654178674351585\n",
      "LR:  0.05\n",
      "[4, 1]\n",
      "0.6416906820365034\n",
      "LR:  0.1\n",
      "[4, 1]\n",
      "0.6426512968299712\n",
      "LR:  0.2\n",
      "[4, 1]\n",
      "0.6426512968299712\n",
      "LR:  0.3\n",
      "[4, 1]\n",
      "0.6445725264169068\n",
      "LR:  0.4\n",
      "[4, 1]\n",
      "0.6455331412103746\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "[4, 1]\n",
      "0.6474543707973103\n",
      "LR:  0.05\n",
      "[4, 1]\n",
      "0.6407300672430355\n",
      "LR:  0.1\n",
      "[4, 1]\n",
      "0.6455331412103746\n",
      "LR:  0.2\n",
      "[4, 1]\n",
      "0.6464937560038425\n",
      "LR:  0.3\n",
      "[4, 1]\n",
      "0.6455331412103746\n",
      "LR:  0.4\n",
      "[4, 1]\n",
      "0.6484149855907781\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "[4, 1]\n",
      "0.643611911623439\n",
      "LR:  0.05\n",
      "[4, 1]\n",
      "0.6407300672430355\n",
      "LR:  0.1\n",
      "[4, 1]\n",
      "0.6464937560038425\n",
      "LR:  0.2\n",
      "[4, 1]\n",
      "0.6455331412103746\n",
      "LR:  0.3\n",
      "[4, 1]\n",
      "0.6474543707973103\n",
      "LR:  0.4\n",
      "[4, 1]\n",
      "0.6493756003842459\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "[4, 1]\n",
      "0.6426512968299712\n",
      "LR:  0.05\n",
      "[4, 1]\n",
      "0.6416906820365034\n",
      "LR:  0.1\n",
      "[4, 1]\n",
      "0.6455331412103746\n",
      "LR:  0.2\n",
      "[4, 1]\n",
      "0.6484149855907781\n",
      "LR:  0.3\n",
      "[4, 1]\n",
      "0.648414985590778\n",
      "LR:  0.4\n",
      "[4, 1]\n",
      "0.6512968299711815\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "[4, 1]\n",
      "0.6426512968299712\n",
      "LR:  0.05\n",
      "[4, 1]\n",
      "0.6455331412103746\n",
      "LR:  0.1\n",
      "[4, 1]\n",
      "0.6464937560038425\n",
      "LR:  0.2\n",
      "[4, 1]\n",
      "0.6493756003842459\n",
      "LR:  0.3\n",
      "[4, 1]\n",
      "0.6503362151777138\n",
      "LR:  0.4\n",
      "[4, 1]\n",
      "0.6512968299711815\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "[4, 1]\n",
      "0.6426512968299711\n",
      "LR:  0.05\n",
      "[4, 1]\n",
      "0.6445725264169068\n",
      "LR:  0.1\n",
      "[4, 1]\n",
      "0.6455331412103746\n",
      "LR:  0.2\n",
      "[4, 1]\n",
      "0.6493756003842459\n",
      "LR:  0.3\n",
      "[4, 1]\n",
      "0.6512968299711815\n",
      "LR:  0.4\n",
      "[4, 1]\n",
      "0.6522574447646493\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "[4, 1]\n",
      "0.6416906820365034\n",
      "LR:  0.05\n",
      "[4, 1]\n",
      "0.6455331412103746\n",
      "LR:  0.1\n",
      "[4, 1]\n",
      "0.6484149855907781\n",
      "LR:  0.2\n",
      "[4, 1]\n",
      "0.6493756003842459\n",
      "LR:  0.3\n",
      "[4, 1]\n",
      "0.6512968299711815\n",
      "LR:  0.4\n",
      "[4, 1]\n",
      "0.6560999039385207\n",
      "(5, 1043)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "[4, 2, 1]\n",
      "0.6099903938520653\n",
      "LR:  0.05\n",
      "[4, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.1\n",
      "[4, 2, 1]\n",
      "0.6282420749279538\n",
      "LR:  0.2\n",
      "[4, 2, 1]\n",
      "0.6234390009606147\n",
      "LR:  0.3\n",
      "[4, 2, 1]\n",
      "0.6532180595581172\n",
      "LR:  0.4\n",
      "[4, 2, 1]\n",
      "0.6551392891450528\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "[4, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.05\n",
      "[4, 2, 1]\n",
      "0.6349663784822286\n",
      "LR:  0.1\n",
      "[4, 2, 1]\n",
      "0.6560999039385206\n",
      "LR:  0.2\n",
      "[4, 2, 1]\n",
      "0.6647454370797311\n",
      "LR:  0.3\n",
      "[4, 2, 1]\n",
      "0.6599423631123918\n",
      "LR:  0.4\n",
      "[4, 2, 1]\n",
      "0.6570605187319885\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "[4, 2, 1]\n",
      "0.6176753121998079\n",
      "LR:  0.05\n",
      "[4, 2, 1]\n",
      "0.6474543707973103\n",
      "LR:  0.1\n",
      "[4, 2, 1]\n",
      "0.6560999039385207\n",
      "LR:  0.2\n",
      "[4, 2, 1]\n",
      "0.6609029779058598\n",
      "LR:  0.3\n",
      "[4, 2, 1]\n",
      "0.6570605187319885\n",
      "LR:  0.4\n",
      "[4, 2, 1]\n",
      "0.6560999039385206\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "[4, 2, 1]\n",
      "0.6051873198847262\n",
      "LR:  0.05\n",
      "[4, 2, 1]\n",
      "0.6455331412103748\n",
      "LR:  0.1\n",
      "[4, 2, 1]\n",
      "0.648414985590778\n",
      "LR:  0.2\n",
      "[4, 2, 1]\n",
      "0.6618635926993276\n",
      "LR:  0.3\n",
      "[4, 2, 1]\n",
      "0.659942363112392\n",
      "LR:  0.4\n",
      "[4, 2, 1]\n",
      "0.6599423631123921\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "[4, 2, 1]\n",
      "0.6128722382324687\n",
      "LR:  0.05\n",
      "[4, 2, 1]\n",
      "0.6570605187319885\n",
      "LR:  0.1\n",
      "[4, 2, 1]\n",
      "0.6560999039385206\n",
      "LR:  0.2\n",
      "[4, 2, 1]\n",
      "0.6589817483189241\n",
      "LR:  0.3\n",
      "[4, 2, 1]\n",
      "0.6589817483189241\n",
      "LR:  0.4\n",
      "[4, 2, 1]\n",
      "0.6589817483189241\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "[4, 2, 1]\n",
      "0.6042267050912584\n",
      "LR:  0.05\n",
      "[4, 2, 1]\n",
      "0.6609029779058598\n",
      "LR:  0.1\n",
      "[4, 2, 1]\n",
      "0.6609029779058597\n",
      "LR:  0.2\n",
      "[4, 2, 1]\n",
      "0.6589817483189241\n",
      "LR:  0.3\n",
      "[4, 2, 1]\n",
      "0.6589817483189241\n",
      "LR:  0.4\n",
      "[4, 2, 1]\n",
      "0.6580211335254562\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "[4, 2, 1]\n",
      "0.6167146974063401\n",
      "LR:  0.05\n",
      "[4, 2, 1]\n",
      "0.6580211335254563\n",
      "LR:  0.1\n",
      "[4, 2, 1]\n",
      "0.6628242074927954\n",
      "LR:  0.2\n",
      "[4, 2, 1]\n",
      "0.6618635926993276\n",
      "LR:  0.3\n",
      "[4, 2, 1]\n",
      "0.6628242074927954\n",
      "LR:  0.4\n",
      "[4, 2, 1]\n",
      "0.6609029779058598\n",
      "(5, 1043)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.05\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.1\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.2\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.3\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.4\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.05\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.1\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.2\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.3\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.4\n",
      "[4, 3, 2, 1]\n",
      "0.6061479346781941\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.05\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.1\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.2\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.3\n",
      "[4, 3, 2, 1]\n",
      "0.6109510086455331\n",
      "LR:  0.4\n",
      "[4, 3, 2, 1]\n",
      "0.6512968299711815\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.05\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.1\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.2\n",
      "[4, 3, 2, 1]\n",
      "0.6080691642651297\n",
      "LR:  0.3\n",
      "[4, 3, 2, 1]\n",
      "0.6167146974063401\n",
      "LR:  0.4\n",
      "[4, 3, 2, 1]\n",
      "0.6532180595581173\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.05\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.1\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.2\n",
      "[4, 3, 2, 1]\n",
      "0.643611911623439\n",
      "LR:  0.3\n",
      "[4, 3, 2, 1]\n",
      "0.6560999039385207\n",
      "LR:  0.4\n",
      "[4, 3, 2, 1]\n",
      "0.6589817483189241\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.05\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.1\n",
      "[4, 3, 2, 1]\n",
      "0.6138328530259366\n",
      "LR:  0.2\n",
      "[4, 3, 2, 1]\n",
      "0.6147934678194044\n",
      "LR:  0.3\n",
      "[4, 3, 2, 1]\n",
      "0.6522574447646493\n",
      "LR:  0.4\n",
      "[4, 3, 2, 1]\n",
      "0.6570605187319885\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.05\n",
      "[4, 3, 2, 1]\n",
      "0.601344860710855\n",
      "LR:  0.1\n",
      "[4, 3, 2, 1]\n",
      "0.6109510086455331\n",
      "LR:  0.2\n",
      "[4, 3, 2, 1]\n",
      "0.6512968299711815\n",
      "LR:  0.3\n",
      "[4, 3, 2, 1]\n",
      "0.6589817483189241\n",
      "LR:  0.4\n",
      "[4, 3, 2, 1]\n",
      "0.6609029779058598\n",
      "(5, 1043)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.05\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.1\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.2\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.3\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.4\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.05\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.1\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.2\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.3\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.4\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.05\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.1\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.2\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.3\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.4\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.05\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.1\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.2\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.3\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.4\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.05\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.1\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.2\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.3\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.4\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.05\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.1\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.2\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.3\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.4\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.05\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.1\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.2\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.3\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n",
      "LR:  0.4\n",
      "[4, 4, 3, 2, 1]\n",
      "0.6032660902977905\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_files = [\"titanic_all.csv\"]\n",
    "learn_rates = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "num_iters = [500, 1000, 1500, 2000, 2500, 3000, 3500]\n",
    "list_hidden_layers = [[], [2], [3, 2], [4, 3, 2]]\n",
    "\n",
    "num_iters_label = num_iters.copy()\n",
    "num_iters_label.insert(0, \"Alpha \\ N° Ite\")\n",
    "\n",
    "k = 3\n",
    "\n",
    "for name in data_files:\n",
    "    for hidden_layers in list_hidden_layers:\n",
    "        result_table = [learn_rates]\n",
    "        data = Leer_Datos(name)\n",
    "        data_np = data.values\n",
    "        np.random.shuffle(data_np)\n",
    "        transposed_data = np.transpose(data_np)\n",
    "        X, y = sep(transposed_data)\n",
    "        norm_data_X, mean_data_X, standard_dev_X = Normalizar_Datos(X)\n",
    "        norm_data = np.concatenate((norm_data_X, y), axis=0)\n",
    "\n",
    "        print(norm_data.shape)\n",
    "        k_folds, size_fold = Crear_k_folds(norm_data, k)\n",
    "        for num_iter in num_iters:\n",
    "            print(\"ITERACIONES: \", num_iter)\n",
    "            learn_rate_row = []\n",
    "            for learn_rate in learn_rates:\n",
    "                print(\"LR: \", learn_rate)\n",
    "                acc_test_total = 0.0\n",
    "                for i in range(k):\n",
    "                    X_train = np.zeros((norm_data.shape[0] - 1, size_fold * (k - 1)))\n",
    "                    X_test = np.zeros((norm_data.shape[0] - 1, size_fold))\n",
    "                    y_train = np.zeros((1, size_fold * (k - 1)))\n",
    "                    y_test = np.zeros((1, size_fold))\n",
    "                    count_sz_fold = 0\n",
    "                    for j in range(k):\n",
    "                        if j == i:\n",
    "                            X_test = k_folds[i]['X']\n",
    "                            y_test = k_folds[i]['y']\n",
    "                        else:\n",
    "                            X_train[:, count_sz_fold:count_sz_fold + size_fold] = k_folds[j]['X']\n",
    "                            y_train[:, count_sz_fold:count_sz_fold + size_fold] = k_folds[j]['y']\n",
    "                            count_sz_fold += size_fold\n",
    "\n",
    "                    model_mlp = hidden_layers.copy()\n",
    "                    model_mlp.insert(0, X_train.shape[0])\n",
    "                    model_mlp.append(1)\n",
    "                    \n",
    "                   \n",
    "\n",
    "                    W_dict, b_dict = Crear_W_b_dict(model_mlp)\n",
    "                    W_dict, b_dict, costs = Gradiente_Descendiente(X_train, y_train, W_dict, b_dict, num_iter,\n",
    "                                                                   learn_rate)\n",
    "                    acc_test = Calcular_Accuracy(X_test, y_test, W_dict, b_dict)\n",
    "                    acc_test_total += acc_test\n",
    "\n",
    "                acc_test_total /= k\n",
    "                print(model_mlp)\n",
    "                print(acc_test_total)\n",
    "                learn_rate_row.append(\"%.4f\" % acc_test_total)\n",
    "                \n",
    "            result_table.append(learn_rate_row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1043)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6561', '0.6513', '0.6378', '0.6446', '0.6484', '0.6484']\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6503', '0.6407', '0.6446', '0.6484', '0.6503', '0.6494']\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6484', '0.6407', '0.6455', '0.6503', '0.6494', '0.6475']\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6503', '0.6436', '0.6484', '0.6513', '0.6503', '0.6494']\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6465', '0.6475', '0.6494', '0.6494', '0.6494', '0.6503']\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6436', '0.6475', '0.6503', '0.6484', '0.6484', '0.6523']\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6417', '0.6494', '0.6503', '0.6494', '0.6503', '0.6542']\n",
      "(5, 1043)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6071', '0.6042', '0.6321', '0.6532', '0.6571', '0.6619']\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6013', '0.6186', '0.6647', '0.6599', '0.6571', '0.6523']\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6013', '0.6494', '0.6590', '0.6551', '0.6503', '0.6513']\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6071', '0.6465', '0.6590', '0.6551', '0.6542', '0.6551']\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6138', '0.6571', '0.6513', '0.6571', '0.6513', '0.6513']\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6100', '0.6638', '0.6532', '0.6503', '0.6503', '0.6513']\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6196', '0.6599', '0.6561', '0.6494', '0.6532', '0.6551']\n",
      "(5, 1043)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6023', '0.6023']\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6023', '0.6186']\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6110', '0.6273']\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6321', '0.6407']\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6590', '0.6484', '0.6513']\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6100', '0.6427', '0.6503', '0.6484']\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6186', '0.6436', '0.6484', '0.6551']\n",
      "(5, 1043)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6023', '0.6023']\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6023', '0.6023']\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6023', '0.6023']\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6023', '0.6023']\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6023', '0.6023']\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6023', '0.6023']\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6023', '0.6023', '0.6023', '0.6023', '0.6023', '0.6023']\n"
     ]
    }
   ],
   "source": [
    "data_files = [\"titanic_all.csv\"]\n",
    "learn_rates = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "num_iters = [500, 1000, 1500, 2000, 2500, 3000, 3500]\n",
    "list_hidden_layers = [[], [2], [3, 2], [4, 3, 2]]\n",
    "\n",
    "num_iters_label = num_iters.copy()\n",
    "num_iters_label.insert(0, \"Alpha \\ N° Ite\")\n",
    "\n",
    "k = 3\n",
    "\n",
    "for name in data_files:\n",
    "    for hidden_layers in list_hidden_layers:\n",
    "        result_table = [learn_rates]\n",
    "        data = Leer_Datos(name)\n",
    "        data_np = data.values\n",
    "        np.random.shuffle(data_np)\n",
    "        transposed_data = np.transpose(data_np)\n",
    "        X, y = sep(transposed_data)\n",
    "        norm_data_X, mean_data_X, standard_dev_X = Normalizar_Datos(X)\n",
    "        norm_data = np.concatenate((norm_data_X, y), axis=0)\n",
    "\n",
    "        print(norm_data.shape)\n",
    "        k_folds, size_fold = Crear_k_folds(norm_data, k)\n",
    "        for num_iter in num_iters:\n",
    "            print(\"ITERACIONES: \", num_iter)\n",
    "            learn_rate_row = []\n",
    "            for learn_rate in learn_rates:\n",
    "                print(\"LR: \", learn_rate)\n",
    "                acc_test_total = 0.0\n",
    "                for i in range(k):\n",
    "                    X_train = np.zeros((norm_data.shape[0] - 1, size_fold * (k - 1)))\n",
    "                    X_test = np.zeros((norm_data.shape[0] - 1, size_fold))\n",
    "                    y_train = np.zeros((1, size_fold * (k - 1)))\n",
    "                    y_test = np.zeros((1, size_fold))\n",
    "                    count_sz_fold = 0\n",
    "                    for j in range(k):\n",
    "                        if j == i:\n",
    "                            X_test = k_folds[i]['X']\n",
    "                            y_test = k_folds[i]['y']\n",
    "                        else:\n",
    "                            X_train[:, count_sz_fold:count_sz_fold + size_fold] = k_folds[j]['X']\n",
    "                            y_train[:, count_sz_fold:count_sz_fold + size_fold] = k_folds[j]['y']\n",
    "                            count_sz_fold += size_fold\n",
    "\n",
    "                    model_mlp = hidden_layers.copy()\n",
    "                    model_mlp.insert(0, X_train.shape[0])\n",
    "                    model_mlp.append(1)\n",
    "                    \n",
    "                   \n",
    "\n",
    "                    W_dict, b_dict = Crear_W_b_dict(model_mlp)\n",
    "                    W_dict, b_dict, costs = Gradiente_Descendiente(X_train, y_train, W_dict, b_dict, num_iter,\n",
    "                                                                   learn_rate)\n",
    "                    acc_test = Calcular_Accuracy(X_test, y_test, W_dict, b_dict)\n",
    "                    acc_test_total += acc_test\n",
    "\n",
    "                acc_test_total /= k\n",
    "               \n",
    "                learn_rate_row.append(\"%.4f\" % acc_test_total)\n",
    "                \n",
    "            result_table.append(learn_rate_row)\n",
    "            print(learn_rate_row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 150)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-17f7f0dedc20>:60: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return -np.divide(y, A_L) + np.divide(1 - y, 1 - A_L)\n",
      "<ipython-input-61-17f7f0dedc20>:67: RuntimeWarning: invalid value encountered in multiply\n",
      "  dZ = np.multiply(dA, dSigmoidal(Z_dict[\"Z%d\" % (l + 1)]))\n",
      "<ipython-input-48-42c5fb3bf39c>:2: RuntimeWarning: divide by zero encountered in log\n",
      "  result = np.sum((y * np.log(X)) + ((1 - y) * np.log(1 - X)))\n",
      "<ipython-input-50-1ff56e0783f8>:4: RuntimeWarning: invalid value encountered in greater\n",
      "  result = A_L > 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.8533', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.8400', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.8533', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.5467', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.3333', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.3333', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.3333', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "(5, 150)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-17f7f0dedc20>:60: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -np.divide(y, A_L) + np.divide(1 - y, 1 - A_L)\n",
      "<ipython-input-48-42c5fb3bf39c>:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  result = np.sum((y * np.log(X)) + ((1 - y) * np.log(1 - X)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.6667', '0.6667', '0.5333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.6667', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "(5, 150)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.6667', '0.6667', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.6667', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.4400', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.3333', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "(5, 150)\n",
      "ITERACIONES:  500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.6667', '0.6667', '0.5067', '0.5067', '0.3333']\n",
      "ITERACIONES:  1000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.6667', '0.5733', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  1500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.6667', '0.5067', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  2000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.5733', '0.5067', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  2500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.5067', '0.5067', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  3000\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.5067', '0.3333', '0.3333', '0.3333', '0.3333']\n",
      "ITERACIONES:  3500\n",
      "LR:  0.01\n",
      "LR:  0.05\n",
      "LR:  0.1\n",
      "LR:  0.2\n",
      "LR:  0.3\n",
      "LR:  0.4\n",
      "['0.6667', '0.5067', '0.3333', '0.3333', '0.3333', '0.3333']\n"
     ]
    }
   ],
   "source": [
    "data_files = [\"iris_all.csv\"]\n",
    "learn_rates = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "num_iters = [500, 1000, 1500, 2000, 2500, 3000, 3500]\n",
    "list_hidden_layers = [[], [2], [3, 2], [4, 3, 2]]\n",
    "\n",
    "num_iters_label = num_iters.copy()\n",
    "num_iters_label.insert(0, \"Alpha \\ N° Ite\")\n",
    "\n",
    "k = 3\n",
    "\n",
    "for name in data_files:\n",
    "    for hidden_layers in list_hidden_layers:\n",
    "        result_table2 = [learn_rates]\n",
    "        data = Leer_Datos(name)\n",
    "        data_np = data.values\n",
    "        np.random.shuffle(data_np)\n",
    "        transposed_data = np.transpose(data_np)\n",
    "        X, y = sep(transposed_data)\n",
    "        norm_data_X, mean_data_X, standard_dev_X = Normalizar_Datos(X)\n",
    "        norm_data = np.concatenate((norm_data_X, y), axis=0)\n",
    "\n",
    "        print(norm_data.shape)\n",
    "        k_folds, size_fold = Crear_k_folds(norm_data, k)\n",
    "        for num_iter in num_iters:\n",
    "            print(\"ITERACIONES: \", num_iter)\n",
    "            learn_rate_row = []\n",
    "            for learn_rate in learn_rates:\n",
    "                print(\"LR: \", learn_rate)\n",
    "                acc_test_total = 0.0\n",
    "                for i in range(k):\n",
    "                    X_train = np.zeros((norm_data.shape[0] - 1, size_fold * (k - 1)))\n",
    "                    X_test = np.zeros((norm_data.shape[0] - 1, size_fold))\n",
    "                    y_train = np.zeros((1, size_fold * (k - 1)))\n",
    "                    y_test = np.zeros((1, size_fold))\n",
    "                    count_sz_fold = 0\n",
    "                    for j in range(k):\n",
    "                        if j == i:\n",
    "                            X_test = k_folds[i]['X']\n",
    "                            y_test = k_folds[i]['y']\n",
    "                        else:\n",
    "                            X_train[:, count_sz_fold:count_sz_fold + size_fold] = k_folds[j]['X']\n",
    "                            y_train[:, count_sz_fold:count_sz_fold + size_fold] = k_folds[j]['y']\n",
    "                            count_sz_fold += size_fold\n",
    "\n",
    "                    model_mlp = hidden_layers.copy()\n",
    "                    model_mlp.insert(0, X_train.shape[0])\n",
    "                    model_mlp.append(1)\n",
    "                    \n",
    "                   \n",
    "\n",
    "                    W_dict, b_dict = Crear_W_b_dict(model_mlp)\n",
    "                    W_dict, b_dict, costs = Gradiente_Descendiente(X_train, y_train, W_dict, b_dict, num_iter,\n",
    "                                                                   learn_rate)\n",
    "                    acc_test = Calcular_Accuracy(X_test, y_test, W_dict, b_dict)\n",
    "                    acc_test_total += acc_test\n",
    "\n",
    "                acc_test_total /= k\n",
    "               \n",
    "                learn_rate_row.append(\"%.4f\" % acc_test_total)\n",
    "                \n",
    "            result_table2.append(learn_rate_row)\n",
    "            print(learn_rate_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
