{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">1. Leer datos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar datos: Glass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos:\n",
    "1. Número de identificación: 1 a 214\n",
    "2. RI: índice de refracción\n",
    "3. Na: Sodio (unidad de medida: porcentaje en peso en el óxido correspondiente, al igual que los atributos 4-10)\n",
    "4. Mg: magnesio\n",
    "5. Al: Aluminio\n",
    "6. Si: silicio\n",
    "7. K: Potasio\n",
    "8. Ca: calcio\n",
    "9. Ba: bario\n",
    "10. Fe: Hierro\n",
    "11. Tipo de vidrio: (atributo de clase)\n",
    "     1. building_windows_float_processed\n",
    "     2. building_windows_non_float_processed\n",
    "     3. vehicle_windows_float_processed\n",
    "     4. vehicle_windows_non_float_processed (ninguno en esta base de datos)\n",
    "     5. contenedores\n",
    "     6. vajilla\n",
    "     7. faros\n",
    "    \n",
    "    \n",
    "Distribución de clases: (de un total de 214 instancias)\n",
    "\n",
    "1. 163 Vidrio de ventana (ventanas de edificios y ventanas de vehículos)\n",
    "     1. 87 flotador procesado\n",
    "         - 70 ventanas de construcción\n",
    "         - 17 ventanas de vehículos\n",
    "     2. 76 procesado sin flotación\n",
    "         - 76 ventanas de construcción\n",
    "         - 0 ventanas de vehículos\n",
    "2. 51 Vidrio no de ventana\n",
    "     - 13 contenedores\n",
    "     - 9 vajillas\n",
    "     - 29 faros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glass shape:  (213, 11)\n"
     ]
    }
   ],
   "source": [
    "glass = pd.read_csv('glass.csv')\n",
    "glass.columns = ['id','ri','na','mg','al','si','k','ca','ba','fe','class']\n",
    "print(\"Glass shape: \", glass.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar datos: Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Train Shape :  (712, 5)\n",
      "Titanic Test Shape :  (712, 5)\n",
      "Titanic Shape:  (1043, 5)\n"
     ]
    }
   ],
   "source": [
    "train_titanic = pd.read_csv('titanic_train.csv', sep=',')\n",
    "test_t = pd.read_csv('titanic_test.csv', sep=',')\n",
    "gender_sub = pd.read_csv('gender_submission.csv', sep=',')\n",
    "gender_sub.PassengerId = gender_sub.PassengerId.astype(float)\n",
    "\n",
    "train_titanic = train_titanic.replace('Q', 0)\n",
    "train_titanic = train_titanic.replace('S', 1)\n",
    "train_titanic = train_titanic.replace('C', 2)\n",
    "train_titanic = train_titanic.replace('male', 0)\n",
    "train_titanic = train_titanic.replace('female', 1)\n",
    "train_titanic = np.array(train_titanic.loc[:,['Sex','Age','Fare','Embarked', 'Survived']])\n",
    "train_titanic = train_titanic[~np.isnan(train_titanic).any(axis=1)]\n",
    "\n",
    "print(\"Titanic Train Shape : \", train_titanic.shape)\n",
    "\n",
    "test1_t = pd.merge(test_t, gender_sub,  how='left', on='PassengerId')\n",
    "test1_t = test1_t.replace('Q', 0)\n",
    "test1_t = test1_t.replace('S', 1)\n",
    "test1_t = test1_t.replace('C', 2)\n",
    "test1_t = test1_t.replace('male', 0)\n",
    "test1_t = test1_t.replace('female', 1)\n",
    "\n",
    "print(\"Titanic Test Shape : \", train_titanic.shape)\n",
    "\n",
    "test_titanic = np.array(test1_t.loc[:,['Sex','Age','Fare','Embarked', 'Survived']])\n",
    "test_titanic = test_titanic[~np.isnan(test_titanic).any(axis=1)]\n",
    "\n",
    "titanic = np.concatenate((train_titanic, test_titanic), axis=0)\n",
    "titanic = pd.DataFrame(data=titanic, columns=['Sex','Age','Fare','Embarked', 'Survived'])\n",
    "\n",
    "print(\"Titanic Shape: \", titanic.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">2. Normalizar datos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalizar_Datos(data):\n",
    "    print(data)\n",
    "    tam = len(data.columns)\n",
    "    y = data.iloc[:,-1]\n",
    "    data = data.iloc[:,:-1]\n",
    "    data = (data - data.mean(axis=0))/data.std(axis=0)\n",
    "    data.insert(tam-1, \"y\", y, True) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex   Age      Fare  Embarked  Survived\n",
      "0     0.0  22.0    7.2500       1.0       0.0\n",
      "1     1.0  38.0   71.2833       2.0       1.0\n",
      "2     1.0  26.0    7.9250       1.0       1.0\n",
      "3     1.0  35.0   53.1000       1.0       1.0\n",
      "4     0.0  35.0    8.0500       1.0       0.0\n",
      "...   ...   ...       ...       ...       ...\n",
      "1038  1.0   3.0   13.7750       1.0       1.0\n",
      "1039  1.0  37.0   90.0000       0.0       1.0\n",
      "1040  1.0  28.0    7.7750       1.0       1.0\n",
      "1041  1.0  39.0  108.9000       2.0       1.0\n",
      "1042  0.0  38.5    7.2500       1.0       0.0\n",
      "\n",
      "[1043 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "titanic_data = Normalizar_Datos(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id       ri     na    mg    al     si     k    ca    ba    fe  class\n",
      "0      2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.00      1\n",
      "1      3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.00      1\n",
      "2      4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.00      1\n",
      "3      5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.00      1\n",
      "4      6  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.00  0.26      1\n",
      "..   ...      ...    ...   ...   ...    ...   ...   ...   ...   ...    ...\n",
      "208  210  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.00      7\n",
      "209  211  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.00      7\n",
      "210  212  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.00      7\n",
      "211  213  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.00      7\n",
      "212  214  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.00      7\n",
      "\n",
      "[213 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "glass_data = Normalizar_Datos(glass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">3. Exactitud - Accuracy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcular_Accuracy(X, y, W_dict, b_dict):\n",
    "    _, A_dict = Forward(X, W_dict, b_dict)\n",
    "    A_L = A_dict[\"A%d\"%(len(A_dict)-1)]\n",
    "    result = A_L > 0.5\n",
    "    result = np.logical_xor(np.logical_not(result), y)\n",
    "    print(\"Y SHAPE\")\n",
    "    print(y.shape)\n",
    "    #return np.sum(result) / y.shape[1]\n",
    "    return np.sum(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">4. KFolds - Multiclase</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFolds(data, k=3, clases=[0, 1]):\n",
    "    list_clases = []\n",
    "    list_indices_break = []\n",
    "    list_folds_clases = []\n",
    "    \n",
    "    #ordenar segun ultima columna\n",
    "    data = data.sort_values(by=[\"y\"]).values\n",
    "\n",
    "    for i in range(1, len(clases)):\n",
    "        #obtener el indice de la primera ocucrrencia de unos\n",
    "        indice_break = np.where(data[:,-1] == clases[i])[0][0]\n",
    "        list_indices_break.append(indice_break)\n",
    "        \n",
    "    #dividar los datos en dos clases\n",
    "    list_clases = np.split(data, list_indices_break)\n",
    "\n",
    "    \n",
    "    #dividir en k folds\n",
    "    for clase in list_clases:\n",
    "        clase = np.array_split(clase, k)\n",
    "        list_folds_clases.append(clase)\n",
    "\n",
    "    datos_split = list()\n",
    "\n",
    "    #distribuir una porcion equitativa de cada clase a cada fold\n",
    "    for i in range(k):\n",
    "        fold = list_folds_clases[0][i]\n",
    "        \n",
    "        #combinar cada fold con una proporcion de cada clase\n",
    "        for j in range(len(list_folds_clases)):\n",
    "            fold = np.concatenate((fold, list_folds_clases[j][i]))\n",
    "\n",
    "        #mezclar los dataFrames\n",
    "        np.random.shuffle(fold)\n",
    "\n",
    "        #separar x e y\n",
    "        x_data = fold[:, :-1]\n",
    "        y_data = fold[:, -1]\n",
    "\n",
    "        datos_split.append([x_data, y_data])\n",
    "\n",
    "    return datos_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 10)\n",
      "(94, 10)\n",
      "(92, 10)\n"
     ]
    }
   ],
   "source": [
    "titanic_folds = kFolds(titanic_data, k=3, clases=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_folds = kFolds(glass_data, k=3, clases=[1,2,3,5,6,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">5. Sigmoidal</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoidal(x):\n",
    "    return 1.0 / (1.0+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Activation(X, W, b):\n",
    "    print(type(X))\n",
    "    print(type(W))\n",
    "    print(X.shape)\n",
    "    print(W.shape)\n",
    "    \n",
    "    Z = np.dot(X,W)  + b\n",
    "    #Z = np.mat(X) * np.mat(W)+ b\n",
    "    A = Sigmoidal(Z)\n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">6. Función de Costo</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcular_Funcion_Costo(X, y):\n",
    "    c = np.sum( (y * np.log(X)) + ((1-y) * np.log(1-X)) )\n",
    "    costo = (-c)/y.shape[1]\n",
    "    return costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">7. Derivada Sigmoidal</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dSigmoidal(D):\n",
    "    return D * (1.0 - D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">8. Forward</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward(X, W, b):\n",
    "    A = X\n",
    "    Z_dict = {}\n",
    "    A_dict = {\"A0\":A}\n",
    "    for l in range(len(W)):\n",
    "        A, Z = Activation( A, W[ \"W%d\"%(l+1) ], b[ \"b%d\"%(l+1) ] )\n",
    "        Z_dict[\"Z%d\"%(l+1)] = Z\n",
    "        A_dict[\"A%d\"%(l+1)] = A\n",
    "    return Z_dict, A_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">9. Backward</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward(W, b, z, A, y, learn_rate):\n",
    "    m = A[\"A0\"].shape[1]\n",
    "    dA = get_dC_dA_L(A[\"A%d\"%(len(A)-1)], y)\n",
    "    for l in reversed(range(len(W))):\n",
    "        dZ = np.multiply(dA, dS(z[\"Z%d\"%(l+1)]))\n",
    "        dW = np.divide(np.dot( dZ, A[\"A%d\"%(l)].T ), m)\n",
    "        db = np.divide(np.sum( dZ, axis=1, keepdims=True ), m)\n",
    "        dA = np.dot( W[\"W%d\"%(l+1)].T, dZ )\n",
    "        W[\"W%d\"%(l+1)] = W[\"W%d\"%(l+1)] - np.multiply(learn_rate, dW)\n",
    "        b[\"b%d\"%(l+1)] = b[\"b%d\"%(l+1)] - np.multiply(learn_rate, db)\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">10. Gradiente descendiente</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradiente_Descendiente(X, y, W, b, iterations, learn_rate):\n",
    "    cost_history = np.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        Z_dict, A_dict = Forward(X, W, b)\n",
    "        W, b = Backward(W, b, Z_dict, A_dict, y, learn_rate)\n",
    "        cost_history[i] = Calcular_Funcion_Costo(A_dict[\"A%d\"%(len(A_dict)-1)], y)\n",
    "    return W, b, cost_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">11. Funciones auxiliares</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_W(cur, prev):\n",
    "    return np.random.rand(cur, prev)\n",
    "def generate_b(b):\n",
    "    return np.random.rand(b, 1)\n",
    "\n",
    "\n",
    "def generator_W_b(layers):\n",
    "    W = {}\n",
    "    b = {}\n",
    "    for l in range(len(layers)-1):\n",
    "        W[\"W%d\"%(l+1)] = generate_W(layers[l], layers[l+1])\n",
    "        b[\"b%d\"%(l+1)] = generate_b(layers[l+1])\n",
    "    return W, b\n",
    "\n",
    "def getNeurons(num_layers=1, neurons=[1]):\n",
    "    lays = []\n",
    "    for i in range(num_layers):\n",
    "        lays.append(random.choice(neurons))\n",
    "    return lays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:10\">12. Experimentos</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Entra\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(559, 4)\n",
      "(4, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(559, 1)\n",
      "(1, 1)\n",
      "Y SHAPE\n",
      "(559,)\n",
      "1\n",
      "Entra\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(556, 4)\n",
      "(4, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(556, 1)\n",
      "(1, 1)\n",
      "Y SHAPE\n",
      "(556,)\n",
      "1\n",
      "Entra\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(556, 4)\n",
      "(4, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(556, 1)\n",
      "(1, 1)\n",
      "Y SHAPE\n",
      "(556,)\n",
      "1\n",
      "Entra\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(559, 4)\n",
      "(4, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (559,2) (2,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-668a3ccc8fb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mweigths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_W_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mweigths_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_history_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradiente_Descendiente\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_fold_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_fold_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweigths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0macc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCalcular_Accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_fold_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_fold_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweigths_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0macc_test_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-174-12de6296bcdf>\u001b[0m in \u001b[0;36mCalcular_Accuracy\u001b[1;34m(X, y, W_dict, b_dict)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mCalcular_Accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mForward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mA_L\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A%d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA_L\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_xor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-157-e64b14dce7c4>\u001b[0m in \u001b[0;36mForward\u001b[1;34m(X, W, b)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mA_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"A0\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;34m\"W%d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;34m\"b%d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mZ_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Z%d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mA_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A%d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-189-86201a36db90>\u001b[0m in \u001b[0;36mActivation\u001b[1;34m(X, W, b)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m#Z = np.mat(X) * np.mat(W)+ b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSigmoidal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (559,2) (2,1) "
     ]
    }
   ],
   "source": [
    "#tasas = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "#iteraciones = [500, 1000, 1500, 2000, 2500, 3000, 3500]\n",
    "tasas = [0.01]\n",
    "iteraciones = [500]\n",
    "num_hidden_layers = [1,2,3,4]\n",
    "num_neurons_per_l = [3,4,5]\n",
    "\n",
    "numFolds = len(titanic_folds)\n",
    "results_titanic = {}\n",
    "weights_titanic = {}\n",
    "matrix_ac = np.random.rand(len(tasas),len(iteraciones),numFolds)\n",
    "\n",
    "for l in num_hidden_layers:\n",
    "    lay = getNeurons(l,num_neurons_per_l)\n",
    "    for i in range(numFolds):\n",
    "        for t in range(len(tasas)):\n",
    "            acc_test_total = 0.0\n",
    "            tasa = tasas[t]\n",
    "            print(len(iteraciones))\n",
    "            for j,it in enumerate(iteraciones):\n",
    "                print(\"Entra\")\n",
    "               \n",
    "            \n",
    "                #actual fold (usado para test)\n",
    "                fold = titanic_folds[i]\n",
    "                test_fold_X = fold[0]\n",
    "                test_fold_y = fold[1]\n",
    "\n",
    "                #los otros dos folds usados para train\n",
    "                fold_2 = titanic_folds[(i+1)%numFolds]\n",
    "                fold_3 = titanic_folds[(i+2)%numFolds]\n",
    "                train_fold_X = np.concatenate((fold_2[0], fold_3[0]), axis=0)\n",
    "                train_fold_y = np.concatenate((fold_2[1], fold_3[1]), axis=0)\n",
    "\n",
    "                act_layers = []\n",
    "\n",
    "                act_layers.append(train_fold_X.shape[1]) \n",
    "                act_layers.append(len(lay))\n",
    "                act_layers.append(1)\n",
    "\n",
    "                weigths, bias = generator_W_b(act_layers)\n",
    "                weigths_r, bias_r, cost_history_r = Gradiente_Descendiente(train_fold_X, train_fold_y, weigths, bias, j, tasa)\n",
    "                acc_test = Calcular_Accuracy(test_fold_X,test_fold_y, weigths_r, bias_r)\n",
    "                acc_test_total += acc_test\n",
    "                \n",
    "                \n",
    "                \n",
    "                '''\n",
    "                weigths = weights_generator(act_layers)\n",
    "                activations = Generar_Activaciones(act_layers)\n",
    "                print(train_fold_y)\n",
    "                weights_r, cost_history_r = Gradiente_Descendiente(train_fold_X, train_fold_y, weigths, it, t, activations)\n",
    "               \n",
    "                matrix_ac[t,j,i] = Calcular_Accuracy(test_fold_X,test_fold_y,new_Weigths,activations)\n",
    "                \n",
    "                \n",
    "                print(len(cost_history_r))\n",
    "                costo_gradiente = cost_history_r[-1]\n",
    "                \n",
    "                results_titanic[\"tasa_\"+str(tasa)+\"_iter_\"+str(iteracion)+\"_fold_\"+str(i)] = costo_gradiente\n",
    "                weights_titanic[\"tasa_\"+str(tasa)+\"_iter_\"+str(iteracion)+\"_fold_\"+str(i)] = weights_r\n",
    "                '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(weights_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de linear SVM:\n",
      " 0.9610244988864143\n",
      "Score de polynomial SVM:\n",
      " 0.9749443207126949\n",
      "Score de sigmoid SVM:\n",
      " 0.717706013363029\n",
      "Score de kernel gausiano SVM:\n",
      " 0.982739420935412\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "# The Dataset comes from:\n",
    "# https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
    "\n",
    "def load(path_test, path_train):\n",
    "  # Load up the data.\n",
    "  with open(path_test, 'r')  as f: testing  = pd.read_csv(f)\n",
    "  with open(path_train, 'r') as f: training = pd.read_csv(f)\n",
    "\n",
    "  # The number of samples between training and testing can vary\n",
    "  # But the number of features better remain the same!\n",
    "  n_features = testing.shape[1]\n",
    "\n",
    "  X_test  = testing.iloc[:, :n_features-1]\n",
    "  X_train = training.iloc[:, :n_features-1]\n",
    "  y_test  = testing.iloc[:,n_features-1].values.ravel()\n",
    "  y_train = training.iloc[:,n_features-1].values.ravel()\n",
    "\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def linear_SVM(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    svc = svm.SVC(kernel='linear', C=1, gamma=0.001)\n",
    "    svc.fit(X_train, y_train) \n",
    "    \n",
    "    # Calcular el score del SVM\n",
    "    score = svc.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "def poly_SVM(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    svc = svm.SVC(kernel='poly', C=1, degree=3, gamma=0.001)\n",
    "    svc.fit(X_train, y_train) \n",
    "    \n",
    "    # Calcular el score del SVM\n",
    "    score = svc.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "def sigmoid_SVM(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    svc = svm.SVC(kernel='sigmoid', C=1, gamma=0.001)\n",
    "    svc.fit(X_train, y_train) \n",
    "    \n",
    "    # Calcular el score del SVM\n",
    "    score = svc.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "def kernel_gausiano_SVM(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    svc = svm.SVC(kernel='rbf', C=1, gamma=0.001)\n",
    "    svc.fit(X_train, y_train) \n",
    "    \n",
    "    # Calcular el score del SVM\n",
    "    score = svc.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cargando datos\n",
    "X_train, X_test, y_train, y_test = load('Datasets/optdigits.tes', 'Datasets/optdigits.tra')\n",
    "\n",
    "score = linear_SVM(X_train, y_train, X_test, y_test)\n",
    "print (\"Score de linear SVM:\\n\", score)\n",
    "\n",
    "score = poly_SVM(X_train, y_train, X_test, y_test)\n",
    "print (\"Score de polynomial SVM:\\n\", score)\n",
    "\n",
    "score = sigmoid_SVM(X_train, y_train, X_test, y_test)\n",
    "print (\"Score de sigmoid SVM:\\n\", score)\n",
    "\n",
    "score = kernel_gausiano_SVM(X_train, y_train, X_test, y_test)\n",
    "print (\"Score de kernel gausiano SVM:\\n\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
