{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42JtVxPD4cjO"
   },
   "source": [
    "Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLqIcrfi4gDR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zbAIsRJ6qMh"
   },
   "source": [
    "Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8hhyjPO6r3s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSJLNQlZ8XF6"
   },
   "source": [
    "Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Slp-NJFi7eAK"
   },
   "outputs": [],
   "source": [
    "def normalizar(X_train, X_test,y_train, y_test):\n",
    "  X_media = np.concatenate((X_train, X_test), axis=0).mean(axis=0)\n",
    "  X_std = np.concatenate((X_train, X_test), axis=0).std(axis=0)\n",
    "  y_media = np.concatenate((y_train, y_test), axis=0).mean()\n",
    "  y_std = np.concatenate((y_train, y_test), axis=0).std()\n",
    "\n",
    "  X_train = (X_train - X_media)/X_std\n",
    "  y_train = (y_train - y_media)/y_std\n",
    "  X_test = (X_test - X_media)/X_std\n",
    "  y_test = (y_test - y_media)/y_std\n",
    "\n",
    "  return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-wz2k_z8RY1"
   },
   "source": [
    "Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjnCHgl8_rpf"
   },
   "source": [
    "$\\theta^{T}x = g(\\theta^{T}x)$\n",
    "\n",
    "$g(z) = \\frac{1}{1+e^{-z}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejRj7NfZ8dLK"
   },
   "outputs": [],
   "source": [
    "# función sigmoidea\n",
    "\n",
    "def predict(X, theta):\n",
    "    z=np.dot(X,theta)\n",
    "    return 1/(1+np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeeiHf63CrSO"
   },
   "source": [
    "**Función de costo para la regresión logística:**\n",
    "\n",
    "*   Elemento de lista\n",
    "*   Elemento de lista\n",
    "\n",
    "\n",
    "$J(\\theta) = - \\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}\\log h_\\theta(x^{(i)})+(1-y^{(i)})\\log(1-h_\\theta(x^{(i)}))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwvnuG0a80tt"
   },
   "outputs": [],
   "source": [
    "def cal_cost(theta, X, y):\n",
    "    y_pred = predict(X, theta)\n",
    "    cross_entropy = y * np.log(y_pred) + (1-y) * np.log(1-y_pred)\n",
    "    return (-1/X.shape[0]) * np.sum(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkfxhCSY8Vea"
   },
   "source": [
    "**Gradiente descendiente**\n",
    "\n",
    "$\\theta_j = \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m (h_{\\theta}(x^{(i)})-y^{(i)})x_j^{(i)}$\n",
    "\n",
    "Donde : $h_{\\theta}(x) = \\frac{1}{1+e^{-z}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tk2uKhu0H85h"
   },
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "theta = np.zeros(n_features)\n",
    "alpha = 0.01 # learning rate\n",
    "iterations = 2000\n",
    "\n",
    "def gradient_descent(X,y,theta):\n",
    "    cost_history = np.zeros(iterations)\n",
    "    for it in range(iterations):\n",
    "        prediction = predict(X, theta)\n",
    "        # m = prediction.shape[0]\n",
    "        theta = theta - (1/prediction.shape[0])*alpha*( X.T.dot((prediction - y)))\n",
    "        cost_history[it]  = cal_cost(theta,X,y)\n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsZfikg8IyRq"
   },
   "source": [
    "**Exactitud (Accuracy)**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvCZv5LUIyhq"
   },
   "outputs": [],
   "source": [
    "def accuracy(X, y, theta):\n",
    "   prediction = predict(X, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KFolds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def listByClass(my_list, clase):\n",
    "    #obtener los indices que corresponden a esa clase\n",
    "    idx_class = [i for i, x in enumerate(my_list) if x == clase]\n",
    "    list_class = np.zeros(len(idx_class))\n",
    "    for i in range (len(idx_class)):\n",
    "        indice = idx_class[i]\n",
    "        list_class[i] = my_list[indice]\n",
    "        \n",
    "    return list_class\n",
    "    \n",
    "def kFolds(datos, k=3):\n",
    "    list_class1 = listByClass(my_list, 0)\n",
    "    list_class2 = listByClass(my_list, 1)\n",
    "    \n",
    "    datos_split = list()\n",
    "    datos = list(datos)\n",
    "    fold_size_class1 = int(len(list_class1) / k)\n",
    "    fold_size_class2 = int(len(list_class2) / k)\n",
    "    \n",
    "    for i in range(k-1):\n",
    "        fold = list()\n",
    "        \n",
    "        #clase 1\n",
    "        startIdx = i * fold_size_class1\n",
    "        endIdx = (i+1) * fold_size_class1\n",
    "        fold.extend(list_class1[startIdx : endIdx])\n",
    "        \n",
    "        #clase 2\n",
    "        startIdx = i * fold_size_class2\n",
    "        endIdx = (i+1) * fold_size_class2\n",
    "        fold.extend(list_class2[startIdx : endIdx])\n",
    "        \n",
    "        datos_split.append(fold)\n",
    "        \n",
    "    #agregar el ultimo subconjunto hasta el final del dataset\n",
    "    fold = list()\n",
    "    startIdx = (k-1) * fold_size_class1\n",
    "    fold.extend(list_class1[startIdx :])\n",
    "    startIdx = (k-1) * fold_size_class2\n",
    "    fold.extend(list_class2[startIdx :])\n",
    "    datos_split.append(fold)\n",
    "    \n",
    "    \n",
    "    return datos_split\n",
    "\n",
    "\n",
    "my_list = [0,0,0,0,0,0,1,1,0,0,1,0,0,1,0,1,1,1,1,0,0]\n",
    "resultFolds = kFolds(my_list, 3)\n",
    "print(resultFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Regresion-Logistica.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
