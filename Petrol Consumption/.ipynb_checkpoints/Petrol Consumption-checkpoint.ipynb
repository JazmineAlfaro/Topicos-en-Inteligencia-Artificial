{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    datos 1  datos 2  datos 3  datos 4  datos 5\n",
      "0      9.00     3571     1976    0.525      541\n",
      "1      9.00     4092     1250    0.572      524\n",
      "2      9.00     3865     1586    0.580      561\n",
      "3      7.50     4870     2351    0.529      414\n",
      "4      8.00     4399      431    0.544      410\n",
      "5     10.00     5342     1333    0.571      457\n",
      "6      8.00     5319    11868    0.451      344\n",
      "7      8.00     5126     2138    0.553      467\n",
      "8      8.00     4447     8577    0.529      464\n",
      "9      7.00     4512     8507    0.552      498\n",
      "10     8.00     4391     5939    0.530      580\n",
      "11     7.50     5126    14186    0.525      471\n",
      "12     7.00     4817     6930    0.574      525\n",
      "13     7.00     4207     6580    0.545      508\n",
      "14     7.00     4332     8159    0.608      566\n",
      "15     7.00     4318    10340    0.586      635\n",
      "16     7.00     4206     8508    0.572      603\n",
      "17     7.00     3718     4725    0.540      714\n",
      "18     7.00     4716     5915    0.724      865\n",
      "19     8.50     4341     6010    0.677      640\n",
      "20     7.00     4593     7834    0.663      649\n",
      "21     8.00     4983      602    0.602      540\n",
      "22     9.00     4897     2449    0.511      464\n",
      "23     9.00     4258     4686    0.517      547\n",
      "24     8.50     4574     2619    0.551      460\n",
      "25     9.00     3721     4746    0.544      566\n",
      "26     8.00     3448     5399    0.548      577\n",
      "27     7.50     3846     9061    0.579      631\n",
      "28     8.00     4188     5975    0.563      574\n",
      "29     9.00     3601     4650    0.493      534\n",
      "30     7.00     3640     6905    0.518      571\n",
      "31     7.00     3333     6594    0.513      554\n",
      "32     8.00     3063     6524    0.578      577\n",
      "33     7.50     3357     4121    0.547      628\n",
      "34     8.00     3528     3495    0.487      487\n",
      "35     6.58     3802     7834    0.629      644\n",
      "36     5.00     4045    17782    0.566      640\n",
      "37     7.00     3897     6385    0.586      704\n",
      "38     8.50     3635     3274    0.663      648\n",
      "39     7.00     4345     3905    0.672      968\n",
      "40     7.00     4449     4639    0.626      587\n",
      "41     7.00     3656     3985    0.563      699\n",
      "42     7.00     4300     3635    0.603      632\n",
      "43     7.00     3745     2611    0.508      591\n",
      "44     6.00     5215     2302    0.672      782\n",
      "45     9.00     4476     3942    0.571      510\n",
      "46     7.00     4296     4083    0.623      610\n",
      "47     7.00     5002     9794    0.593      524\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Libro2.csv', sep=';')\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    datos 1  datos 2  datos 3  datos 4  datos 5  is_train\n",
      "1      9.00     4092     1250    0.572      524      True\n",
      "4      8.00     4399      431    0.544      410      True\n",
      "6      8.00     5319    11868    0.451      344      True\n",
      "7      8.00     5126     2138    0.553      467      True\n",
      "8      8.00     4447     8577    0.529      464      True\n",
      "9      7.00     4512     8507    0.552      498      True\n",
      "12     7.00     4817     6930    0.574      525      True\n",
      "14     7.00     4332     8159    0.608      566      True\n",
      "15     7.00     4318    10340    0.586      635      True\n",
      "16     7.00     4206     8508    0.572      603      True\n",
      "19     8.50     4341     6010    0.677      640      True\n",
      "21     8.00     4983      602    0.602      540      True\n",
      "22     9.00     4897     2449    0.511      464      True\n",
      "23     9.00     4258     4686    0.517      547      True\n",
      "25     9.00     3721     4746    0.544      566      True\n",
      "26     8.00     3448     5399    0.548      577      True\n",
      "27     7.50     3846     9061    0.579      631      True\n",
      "28     8.00     4188     5975    0.563      574      True\n",
      "29     9.00     3601     4650    0.493      534      True\n",
      "31     7.00     3333     6594    0.513      554      True\n",
      "32     8.00     3063     6524    0.578      577      True\n",
      "33     7.50     3357     4121    0.547      628      True\n",
      "34     8.00     3528     3495    0.487      487      True\n",
      "35     6.58     3802     7834    0.629      644      True\n",
      "37     7.00     3897     6385    0.586      704      True\n",
      "39     7.00     4345     3905    0.672      968      True\n",
      "41     7.00     3656     3985    0.563      699      True\n",
      "42     7.00     4300     3635    0.603      632      True\n",
      "43     7.00     3745     2611    0.508      591      True\n",
      "44     6.00     5215     2302    0.672      782      True\n",
      "46     7.00     4296     4083    0.623      610      True\n",
      "47     7.00     5002     9794    0.593      524      True\n",
      "    datos 1  datos 2  datos 3  datos 4  datos 5  is_train\n",
      "0       9.0     3571     1976    0.525      541     False\n",
      "2       9.0     3865     1586    0.580      561     False\n",
      "3       7.5     4870     2351    0.529      414     False\n",
      "5      10.0     5342     1333    0.571      457     False\n",
      "10      8.0     4391     5939    0.530      580     False\n",
      "11      7.5     5126    14186    0.525      471     False\n",
      "13      7.0     4207     6580    0.545      508     False\n",
      "17      7.0     3718     4725    0.540      714     False\n",
      "18      7.0     4716     5915    0.724      865     False\n",
      "20      7.0     4593     7834    0.663      649     False\n",
      "24      8.5     4574     2619    0.551      460     False\n",
      "30      7.0     3640     6905    0.518      571     False\n",
      "36      5.0     4045    17782    0.566      640     False\n",
      "38      8.5     3635     3274    0.663      648     False\n",
      "40      7.0     4449     4639    0.626      587     False\n",
      "45      9.0     4476     3942    0.571      510     False\n",
      "Ejemplos usados para entrenar:  32\n",
      "Ejemplos usados para test:  16\n"
     ]
    }
   ],
   "source": [
    "p_train = 0.70 # Porcentaje de train.\n",
    "\n",
    "data['is_train'] = np.random.uniform(0, 1, len(data)) <= p_train\n",
    "train, test = data[data['is_train']==True], data[data['is_train']==False]\n",
    "data = data.drop('is_train', 1)\n",
    "print(train)\n",
    "print(test)\n",
    "\n",
    "print(\"Ejemplos usados para entrenar: \", len(train))\n",
    "print(\"Ejemplos usados para test: \", len(test))\n",
    "\n",
    "train.to_csv('train_petrol.csv')\n",
    "test.to_csv('test_petrol.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_petrol.csv')\n",
    "test = pd.read_csv('test_petrol.csv')\n",
    "\n",
    "\n",
    "X_train = train.iloc[:, 1:5]\n",
    "y_train = train.iloc[:,5]\n",
    "\n",
    "X_test = test.iloc[:, 1:5]\n",
    "y_test = test.iloc[:,5]\n",
    "\n",
    "#print(X_train)\n",
    "#print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_media = np.concatenate((X_train, X_test), axis=0).mean(axis=0)\n",
    "X_std = np.concatenate((X_train, X_test), axis=0).std(axis=0)\n",
    "y_media = np.concatenate((y_train, y_test), axis=0).mean()\n",
    "y_std = np.concatenate((y_train, y_test), axis=0).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train = (X_train - X_media)/X_std\n",
    "y_train = (y_train - y_media)/y_std\n",
    "X_test = (X_test - X_media)/X_std\n",
    "y_test = (y_test - y_media)/y_std\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 5)\n",
      "[[ 1.          1.4154413  -0.26396904 -1.24905478  0.03036408]\n",
      " [ 1.          0.35253169  0.27688855 -1.48610625 -0.47975254]\n",
      " [ 1.          0.35253169  1.89769956  1.82422057 -2.17406847]\n",
      " [ 1.          0.35253169  1.5576816  -0.99203194 -0.31578648]\n",
      " [ 1.          0.35253169  0.3614526   0.87167309 -0.7530293 ]\n",
      " [ 1.         -0.71037792  0.47596642  0.85141228 -0.33400493]\n",
      " [ 1.         -0.71037792  1.01330051  0.39496518  0.06680099]\n",
      " [ 1.         -0.71037792  0.15885122  0.75068711  0.68622832]\n",
      " [ 1.         -0.71037792  0.13418671  1.38195604  0.2854224 ]\n",
      " [ 1.         -0.71037792 -0.06312941  0.85170172  0.03036408]\n",
      " [ 1.          0.88398649  0.17470698  0.12868026  1.94330142]\n",
      " [ 1.          0.35253169  1.30575119 -1.43661199  0.57691761]\n",
      " [ 1.          1.4154413   1.1542406  -0.90201606 -1.08096142]\n",
      " [ 1.          1.4154413   0.02848164 -0.25453848 -0.97165071]\n",
      " [ 1.          1.4154413  -0.9175787  -0.23717207 -0.47975254]\n",
      " [ 1.          0.35253169 -1.39853675 -0.04816766 -0.40687874]\n",
      " [ 1.         -0.17892312 -0.69735981  1.01176211  0.15789324]\n",
      " [ 1.          0.35253169 -0.09484093  0.11854986 -0.13360197]\n",
      " [ 1.          1.4154413  -1.12898883 -0.26495832 -1.40889353]\n",
      " [ 1.         -0.71037792 -1.60113813  0.2977133  -1.04452452]\n",
      " [ 1.          0.35253169 -2.07681092  0.27745249  0.13967479]\n",
      " [ 1.         -0.17892312 -1.5588561  -0.41807215 -0.42509719]\n",
      " [ 1.          0.35253169 -1.25759666 -0.59926168 -1.51820424]\n",
      " [ 1.         -1.15679996 -0.77487686  0.65661907  1.06881578]\n",
      " [ 1.         -0.71037792 -0.60751051  0.23722031  0.2854224 ]\n",
      " [ 1.         -0.71037792  0.18175399 -0.48059122  1.85220917]\n",
      " [ 1.         -0.71037792 -1.03209252 -0.45743601 -0.13360197]\n",
      " [ 1.         -0.71037792  0.10247519 -0.55874006  0.59513606]\n",
      " [ 1.         -0.71037792 -0.87529667 -0.85512676 -1.13561677]\n",
      " [ 1.         -1.77328753  1.71447745 -0.94456376  1.85220917]\n",
      " [ 1.         -0.71037792  0.09542818 -0.42907088  0.95950508]\n",
      " [ 1.         -0.71037792  1.33922446  1.22392173  0.41295155]]\n"
     ]
    }
   ],
   "source": [
    "n_exa_train = len(y_train)\n",
    "n_exa_test = len(y_test)\n",
    "\n",
    "X_train = np.concatenate((np.ones([n_exa_train, 1]), X_train), axis=1)\n",
    "X_test = np.concatenate((np.ones([n_exa_test, 1]), X_test), axis=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, data):\n",
    "    return np.dot(data, theta)\n",
    "# print(predict(theta, X_train).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = X.shape[0]\n",
    "\n",
    "def cal_cost(theta, X, y):\n",
    "    y_pred_test = predict(theta, X)\n",
    "    to_sum = (y_pred_test - y) ** 2\n",
    "    return np.sum(to_sum) / (X.shape[0]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "theta = np.zeros(n_features)\n",
    "alpha = 0.01 # learning rate\n",
    "iterations = 2000\n",
    "\n",
    "def gradient_descent(X,y,theta):\n",
    "    cost_history = np.zeros(iterations)\n",
    "    for it in range(iterations):\n",
    "        prediction = predict(theta, X)\n",
    "        # m = prediction.shape[0]\n",
    "        theta = theta - (1/prediction.shape[0])*alpha*( X.T.dot((prediction - y)))\n",
    "        cost_history[it]  = cal_cost(theta,X,y)\n",
    "    return theta, cost_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01424402 -0.28653858 -0.33433636 -0.13068401  0.68658193]\n",
      "0.15105625262887\n"
     ]
    }
   ],
   "source": [
    "theta_r, cost_history_r = gradient_descent(X_train, y_train, theta)\n",
    "print(theta_r)\n",
    "cost = cal_cost(theta_r,X_test, y_test)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_history_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
